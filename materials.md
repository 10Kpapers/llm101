---
layout: page
title: Materials
permalink: /materials/
style: |
  ul li {
    list-style-type: disc !important;
  }
  ul li ul li {
    list-style-type: circle !important;
  }
---

<!-- {% include image.html url="/_images/cover2.jpg" width=175 align="right" %} -->

## 参考课程


- [karpathy/LLM101n](https://github.com/karpathy/LLM101n)
- https://github.com/mlabonne/llm-course<!-- - 有一些jupyter notebook可以作为代码实践课的资料 -->
- https://huggingface.co/learn/nlp-course/chapter1/1 <!-- - HF有好几门课程，NLP课程主要是介绍如何使用HF自家的开源框架，包括transformers、datasets、tokenizers、accelerate，几乎没有理论部分，侧重代码实践 -->
- 👍 [港中大（深圳）CSC 6203 Large Language Models](https://llm-course.github.io/)
- [https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)
- [https://cohere.com/llmu](https://cohere.com/llmu)
- [https://www.deeplearning.ai/courses/](https://www.deeplearning.ai/courses/)
- 👍 [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/)
- [Stanford Diyi Yang CS 329X: Human-Centered LLMs](https://web.stanford.edu/class/cs329x/)
- 👍 [伯克利 LLM Agents](https://rdi.berkeley.edu/llm-agents/f24)
- 👍 [斯坦福 2022 CS324 - Large Language Models](https://stanford-cs324.github.io/winter2022/)
- 👍 [斯坦福 2024 CS336: Language Modeling from Scratch](https://stanford-cs336.github.io/spring2024/)
- [斯坦福 2022 CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/)
- 👍 [JHU CS 601.471/671 NLP: Self-supervised Models](https://self-supervised.cs.jhu.edu/sp2024/)
- 👍 [JHU CS 601.771 Advances in Self-supervised Models](https://self-supervised.cs.jhu.edu/fa2024/)
- 👍 [CMU 2024 LLM Sytems](https://llmsystem.github.io/llmsystem2024spring/)
- [CMU 2022 CS 11-711 Advanced NLP](https://www.phontron.com/class/anlp2022/description.html#)
- [CMU Advanced NLP Fall 2024](https://phontron.com/class/anlp-fall2024/)
- [CMU Advanced NLP Spring 2024](https://phontron.com/class/anlp2024/)
- 👍 [CMU Large Language Models: Methods and Applications / Fall 2024](https://cmu-llms.org/)
- [CMU 2019 Machine translation and sequence-to-sequence models](https://www.phontron.com/class/mtandseq2seq2019/schedule.html#)
- [CMU 2024 Advanced Topics in MultiModal Machine Learning](https://cmu-multicomp-lab.github.io/adv-mmml-course/spring2024/)
- [CMU 2023 MultiModal Machine Learning](https://cmu-multicomp-lab.github.io/mmml-course/fall2023/)
- [MIT Natural Language Processing (6.806-864)](https://www.mit.edu/~jda/teaching/6.864/)
- [MIT 2024 6.861* Quantitative Methods for NLP](https://mit-6861.github.io/schedule)
- [普林斯顿 2024 COS 484: Natural Language Processing](https://princeton-nlp.github.io/cos484/)
- [普林斯顿 2021 COS 584: Advanced Natural Language Processing](https://princeton-nlp.github.io/cos484/cos584)
- 👍 [普林斯顿 Danqi Chen 2024 COS 597R: Deep Dive into Large Language Models](https://princeton-cos597r.github.io/)
- [普林斯顿 Danqi Chen 2022 COS 597G: Understanding Large Language Models](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
- [普林斯顿 COS 597F: Embodied Language Understanding](https://sites.google.com/princeton.edu/cos597f)
- [伯克利 2023 Natural Language Processing](https://people.ischool.berkeley.edu/~dbamman//nlp23.html)
- 👍 [ETH Large Language Models, Spring 2024](https://rycolab.io/classes/llm-s24/)
- 👍 [UT Austin CS388: Natural Language Processing (Spring 2024)](https://www.cs.utexas.edu/~gdurrett/courses/sp2024/cs388.shtml)

- [~~CSE 256: Statistical Natural Language Processing~~](https://cseweb.ucsd.edu//~nnakashole/teaching/256_sp19.html)


## 参考书

<!-- Alan Turing and Noam Chomsky: Very Famous Book -->

<!-- ## Additional Course Materials

* If you are not familiar with Python programming, use any online tutorial to get a handle of it.
* [Material #1](http://www.example.com/): how a computer chess player thinks!
* [Material #2](http://www.example.com/): how a computer chess player thinks!
* [Material #3](http://www.example.com/): how a computer chess player thinks!
* [Material #4](http://www.example.com/): how a computer chess player thinks!
* [Material #5](http://www.example.com/): how a computer chess player thinks! -->
