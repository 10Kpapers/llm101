<ul>
  <li>NLP中Encoder-Decoder框架和注意力机制(Attention)</li>
  <li>阅读论文 Attention is All you Need 熟悉Transformer</li>
  <li>代码实践：阅读The Annotated Transformer代码</li>
</ul>

<!-- **Suggested Readings:**
- [Readings 1](http://example.com)
- [Readings 2](http://example.com) -->
