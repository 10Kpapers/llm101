<ul>
  <li>GPT-1 &amp;&amp; GPT-2
    <ul>
      <li>NLP中的预训练-微调范式: CoVe、ELMo、ULMFiT、GPT-1、BERT、GPT-2</li>
      <li>GPT-1 &amp;&amp; GPT-2: Pre-traring LM + Large scale  ==&gt; zero-shot</li>
      <li>编程实践：训练124M GPT-2</li>
    </ul>
  </li>
  <li>GPT-3 and Beyond
    <ul>
      <li>Scaling Laws、涌现、幻觉、位置编码、合成数据、提示工程、SLMs …
<!-- - Prompt Engineering放在LLM调用API的实践课程里面，提供openai api和deepseek api两个版本的colab notebook --></li>
    </ul>
  </li>
</ul>

<!-- **Suggested Readings:** -->
<!-- - [Readings 1](http://example.com)
- [Readings 2](http://example.com) -->
