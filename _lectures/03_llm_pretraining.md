---
type: lecture
date: 2024-11-18T8:00:00+4:30
title: LLM Pre-training and Beyong
tldr: "Short text to discribe what this lecture is about."
thumbnail: /static_files/presentations/lec.jpg
# links: 
#     - url: /static_files/presentations/lec.zip
#       name: notes
#     - url: /static_files/presentations/code.zip
#       name: codes
#     - url: https://google.com
#       name: slides
---
- GPT-1 && GPT-2
    - NLP中的预训练-微调范式: CoVe、ELMo、ULMFiT、GPT-1、BERT、GPT-2
    - GPT-1 && GPT-2: Pre-traring LM + Large scale  ==> zero-shot 
    - 编程实践：训练124M GPT-2
- GPT-3 and Beyond
    - Scaling Laws、涌现、幻觉、位置编码、合成数据、提示工程、SLMs ...
<!-- - Prompt Engineering放在LLM调用API的实践课程里面，提供openai api和deepseek api两个版本的colab notebook -->

<!-- **Suggested Readings:** -->
<!-- - [Readings 1](http://example.com)
- [Readings 2](http://example.com) -->
